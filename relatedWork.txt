1.Pythia: Identifying Dangerous Data-flows in Django-based Applications
    6 pages
    --abstract
    Web frameworks like django provide default security mechanisms
        however these can be disabled by the developers, introducing vulns like xss and csrf 

    Frameworks problems:
        complexity, template usage, inheritance mechanisms

    Goal: Pythia: django framework analyser
        To identify potentially dangerous data flows that can lead to XSS and CSRF defects
        -
        Pythia is the first mechanism to consider framework-specific elements in its analysis == like Django's templates.

    ----intro
    Development frameworks are mainstream
    Such frameworks include by default security features 
    However, on many occasions developers need to disable such features to allow for specific functionalities.
        which brings back vulns 
    
    Django uses MTV Model-Template-View (semi relevant for later)
    Vuln detection within frameworks is hard cause of complexity
        -inheritance mechanisms e.g. in django a template inherits another with disabled security checks

    Pythia, a mechanism that analyzes Django-based applications to identify potentially dangerous data paths. 
    It checks if dangerous code constructs (i.e. the ones used to bypass the security checks provided by the framework) are in the code
    Then, by performing data-flow analysis it examines all critical application parts to identify if any data that may incorporate user input reaches the constructs identified in the first step.
    (the bypassing mechanisms are the sinks..., sources are user input)?

    Standard ideas (Abstract Syntax Tree (ast) analysis) and terms (sources and sinks)
    But it also takes into account the complicated architecture and the various mechanisms (INHERITANCE) and features (TEMPLATES) of Django

    ----django
    A serious issue emerges when this (security mechanisms) bypassing happens in TEMPLATES, 
        a feature that provides a way to generate html dynamically.
        Templates contain static parts, together with some special syntax describing how the dynamic content will be inserted.

    To track such a vulnerability is not trivial because templates can either INCLUDE or INHERIT other templates

    ----approach
    To do so, Pythia analyzes an application’s VIEWS and TEMPLATES, leaving out MODELS (MTV) as they are useless
    First, Pythia searches for specific constructs, which we call sinks, marking any affected templates and then, 
        examines views to identify (1) if untrusted data can reach the elements identified in the first step, 
        (2) if other sinks are being used by the views.
    --sinks 
    A sink method depicts a coding construct where the hazard might take place. 
        In our case, a sink involves an invocation that bypasses the default security mechanisms of a Django Application.

    There are:
        in-view sinks
        template sinks

    In-view sinks only affects a particular View, 
    While template sinks may affect all the views that use those templates

    Template sinks are filters like safeseq/safe, results in not filtering out dangerous characters and marking variables as safe 
    In view sinks like @csrf_exempt, can lead to XSS (useless info)

    To trace dangerous data flows, Pythia expects as input 2 lists:
        one containing in view sinks
        and other containing template sinks

    --analysis-algorithm
    1. Get all project templates and generates their corresponding Abstract Syntax Trees
    2.Then, starting from the root node of each ast, it recursively traverses all children nodes 
        searching for variables that reach a sink method.
        when Pythia identifies a sink, it marks the template as potentially dangerous
            If the current template extends or includes another one, the approach goes on to examine the other template too. 
                In this way it creates a path that is recorded when a sink is found
                When a dangerous path is found, the current node and the template ancestry are kept in a key-value store 
                in order to be cross-examined in the second stage
    3.Then, it traverses the ast of each View to identify:
        the templates that are being used and the data that each template requires to render the page. 
            Finally, the results are being cross-examined in order to find unsafe data paths.
    (n percebi 100%)
    First it analyzes templates to get the linked paths of unsafe shit?
    Then analyzes views to see 1.if they use those templates, 2.if they contain vulns on their own (inviewsinks)?
    ya okay exato figura 2:
        1. Analyze templates: search for  template-sinks and record all affected templates (linked list kinda)
        2. Analyze views:
            2.1 ) find which Templates those views use
            2.2 ) search for inview-sinks
    --
    Pythia requires the ast of a template
        so it creates ast of templates at runtime
        dynamic (django's templates ast creation) + static (rest)
    --
    authors present example cases of false positives and false negatives (4.5)
    --
    related work section, mentions other tools..
    --
    done
    -----------------

2. Scalable Taint Specification Inference with Big Code
    ~14 pages, skip ML

    Uses ML 
        -semi supervised
    Scalable

    Learns from dataset of provided example programs
        in order to infer taint specification- sets of sources,sinks,sanitizers
            while requiring few manual annotations.

    so this whole thing is about automatically getting taint specification, not so much about the analysis itself
    --

    While useful, all of these tools inherently rely on an existing specification that precisely describes the set of sources, sanitizers, and sinks the analyzer should consider. We refer to such a specification as a TAINT SPECIFICATION.
        -pythia needs you to provide the input lists

    Key Challenge: Obtaining a Taint Specification
        Way to many and different frameworks and APIs
            one would have to inspect how information flows in and out of that API and how that information is used. (classic way?)

    Some other taint specification learning tools (related work to them):
        are fully supervised (ml), anotate all sources sinks 
        do not scale 
        target strongly typed languages (not python)

    In this work we propose a new, scalable method for learning likely taint specifications in a semi-supervised manner. 
    Given an input dataset of programs (D) where only a very small subset of the APIs (AM) used by programs in (D) is manually annotated, our method infers specifications for the remaining, much larger un-annotated set of APIs (AU) used by programs in (D)
    our approach leverages interactions among the APIs in (AU) and (AM)
    --till here, abstract and intro

    creates information flow graphs like anything else
        check if flows passes through sanitizer

    Encoding
        Seldon takes as input the propagation graphs of many applications, where the role of most events is unknown. 
        For each event in the graph, it generates variables whose scores indicate the likelihood of this event having a particular role. 
            For example, referring to event request.files['f'].filename as a, 
                it introduces three variables, a_src, a_san, a_sink
                    a_src=0.98 means that event a most likely is a source.

        As a next step, Seldon generates a constraint system that encodes reasonable assumptions on valid scores
            For example, constraint (1) encodes the belief that, if a is source (i.e., a src is high), and b is sanitizer (i.e., b san is high) then at least one of the events receiving information flow from b must be a sink
    --
    Propogation graphs.. of information flow..
    --

    idk kinda boring + ml + ratio
    --
    Seldon relies on a highquality dataset and on a correctly annotated (but small) seed specification (AM?).
    

3. PyT - A Static Analysis Tool for Detecting Security Vulnerabilities in Python Web Applications
    100+ pages

    Static analysis tool PyT 
        created to detect security vulnerabilities in Python web applications, in particular using the framework Flask
    An AST is built by the builtin AST library, and a CFG (control flow graph) is built from the AST
    The resulting CFG is then processed so Flask specific features are taken into account.

    ---
    Ch 6 

    Uses cfg..
    lattices whathever that is, and some fixed point algorithm thingy
    --
    Ch 7
    Process:
    • The source code is parsed to an abstract syntax tree (denoted as AST) 
    • The AST is systematically traversed and turned into a control flow graph
    • The resulting CFG is prepared for the analysis by a framework adaptor,
        The default adaptor is the Flask adaptor, but a similar module for Django applications could be devised.
    • The fixed point algorithm is applied on the CFG and the resulting constraints
        are annotated on each CFG node
    • At last the annotated CFG is investigated, and a log is provided to the user 
        giving precise information about the potential vulnerabilities found by the analysis
    -
    i find nothing distinguishable about this :/

--------------
Make sure that you refer at least to the 3 papers given above, and try to include 2 other that you find via these papers' references or via eg. Google Scholar.
    -bro..
-------------
Concepts:

-Imprecisions
• A mechanism that deems a program insecure, is said to positively detect a security violation.
    False positive - if the detected issue is not a security violation
• A mechanism that deems a program secure, is said to negatively detect any security error.
    False negative - if the problem in fact contained a security violation

If S-secure programs, and A-accepted programs (by the tool):
    A c S -> todos os accepted sao seguros, no false negatives == SOUND
        se todos os accepted sao de facto seguros, é impossivel q uma vuln escape (q reporte q é seguro, e nao seja)
    S c A -> todos os seguros sao accepted, no false positives == COMPLETE
        se todos os seguros sao accepted, se for reportado inseguro, é mmo inseguro (pq se fosse seguro era accepted)
    A = S -> PRECISE

Programs are usually
    unsound (too permissive) 
        there are false negatives (escapam vulns)
    or 
    incomplete (too conservative)
        there are false positives (programas seguros sao barrados)
            cool because no vulns escape

-Static analysis vs Dynamic analysis (self explainatory)

-Complexity of tools
• String matcher - runs directly over source code.
• Lexical analyzer - runs over the tokens generated by the scanner.
• Semantic analyzer - runs over the syntax tree generated by the parser. - projetoiguess
